{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import random\n",
    "import time\n",
    "import torch.utils.data\n",
    "\n",
    "sys.path.append(\"../src/\")\n",
    "import data_reader as dr\n",
    "from evaluate import Evaluation\n",
    "from lstm import LSTM\n",
    "from loss_function import loss_function\n",
    "from loss_function import cs\n",
    "from meter import AUCMeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x, dim):\n",
    "    l2 = torch.norm(x, 2, dim)#.expand_as(x)\n",
    "    l2 = torch.unsqueeze(l2, 2)\n",
    "    l2 = l2.expand_as(x)\n",
    "    return x / l2.clamp(min = 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(data, is_training, model, optimizer):\n",
    "    '''\n",
    "    Train model for one pass of train data, and return loss, acccuracy\n",
    "    '''\n",
    "    # the number of candidates for each question is not the same, so has to set batch_size=1 ?\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        data,\n",
    "        #batch_size=40,\n",
    "        drop_last=False)\n",
    "\n",
    "    #losses = []\n",
    "    scores = []\n",
    "    targets = []\n",
    "\n",
    "    if is_training:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    for batch in data_loader:\n",
    "        pid_title = torch.unsqueeze(Variable(batch['pid_title']), 1)\n",
    "        pid_body = torch.unsqueeze(Variable(batch['pid_body']), 1)\n",
    "        rest_title = Variable(batch['rest_title'])\n",
    "        rest_body = Variable(batch['rest_body'])\n",
    "        \n",
    "        pid_title_pad = torch.unsqueeze(Variable(batch['pid_title_pad']), 1)\n",
    "        pid_body_pad = torch.unsqueeze(Variable(batch['pid_body_pad']), 1)\n",
    "        rest_title_pad = Variable(batch['rest_title_pad'])\n",
    "        rest_body_pad = Variable(batch['rest_body_pad'])\n",
    "        \n",
    "        pid_title, pid_body = pid_title.cuda(), pid_body.cuda()\n",
    "        rest_title, rest_body = rest_title.cuda(), rest_body.cuda()\n",
    "        pid_title_pad, pid_body_pad = pid_title_pad.cuda(), pid_body_pad.cuda()\n",
    "        rest_title_pad, rest_body_pad = rest_title_pad.cuda(), rest_body_pad.cuda()\n",
    "        \n",
    "        if is_training:\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        pt = model(pid_title)\n",
    "        pb = model(pid_body)\n",
    "        rt = model(rest_title)\n",
    "        rb = model(rest_body)\n",
    "        \n",
    "        pt = normalize(pt, 2)\n",
    "        pb = normalize(pb, 2)\n",
    "        rt = normalize(rt, 2)\n",
    "        rb = normalize(rb, 2)\n",
    "        \n",
    "        # we need to take the mean pooling taking into account the padding\n",
    "        # tensors are of dim batch_size x samples x output_size x (len - kernel + 1)\n",
    "        # pad tensors are of dim batch_size x samples x (len - kernel + 1)\n",
    "        \n",
    "        pid_title_pad_ex = torch.unsqueeze(pid_title_pad, 2).expand_as(pt)\n",
    "        pid_body_pad_ex = torch.unsqueeze(pid_body_pad, 2).expand_as(pb)\n",
    "        rest_title_pad_ex = torch.unsqueeze(rest_title_pad, 2).expand_as(rt)\n",
    "        rest_body_pad_ex = torch.unsqueeze(rest_body_pad, 2).expand_as(rb)\n",
    "        \n",
    "        pt = torch.sum(pt * pid_title_pad_ex, dim = 3)\n",
    "        pb = torch.sum(pb * pid_body_pad_ex, dim = 3)\n",
    "        rt = torch.sum(rt * rest_title_pad_ex, dim = 3)\n",
    "        rb = torch.sum(rb * rest_body_pad_ex, dim = 3)\n",
    "        \n",
    "        # tensors are of dim batch_size x samples x output_size\n",
    "        # need to scale down because not all uniformly padded\n",
    "        \n",
    "        ptp_norm = torch.unsqueeze(torch.sum(pid_title_pad, dim = 2).clamp(min = 1), 2).expand_as(pt)\n",
    "        pbp_norm = torch.unsqueeze(torch.sum(pid_body_pad, dim = 2).clamp(min = 1), 2).expand_as(pb)\n",
    "        rtp_norm = torch.unsqueeze(torch.sum(rest_title_pad, dim = 2).clamp(min = 1), 2).expand_as(rt)\n",
    "        rbp_norm = torch.unsqueeze(torch.sum(rest_body_pad, dim = 2).clamp(min = 1), 2).expand_as(rb)\n",
    "            \n",
    "        pt = pt / ptp_norm\n",
    "        pb = pb / pbp_norm\n",
    "        rt = rt / rtp_norm\n",
    "        rb = rb / rbp_norm\n",
    "        \n",
    "        pid_tensor = (pt + pb)/2\n",
    "        rest_tensor = (rt + rb)/2\n",
    "        \n",
    "        if is_training:\n",
    "            pass\n",
    "        else:\n",
    "            expanded = pid_tensor.expand_as(rest_tensor)\n",
    "            similarity = cs(expanded, rest_tensor, dim=2)#.squeeze(2)\n",
    "            similarity = torch.FloatTensor(similarity.data.cpu().numpy())\n",
    "            labels = batch['labels']\n",
    "            \n",
    "            for sim in similarity:\n",
    "                scores.append(sim)\n",
    "            targets.extend(labels[0])\n",
    "            \n",
    "    # Calculate epoch level scores\n",
    "    if is_training:\n",
    "        pass\n",
    "    else:\n",
    "        aucmeter = AUCMeter()\n",
    "        aucmeter.reset()\n",
    "        \n",
    "        output = torch.cat(scores)\n",
    "        expect = torch.LongTensor(targets)\n",
    "        aucmeter.add(output, expect)\n",
    "        return aucmeter.value(max_fpr=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_path = \"../data_Android/corpus.tsv.gz\"\n",
    "\n",
    "corpus = dr.read_corpus(corpus_path)\n",
    "\n",
    "#embedding_path = \"../data/vectors_pruned.200.txt.gz\"\n",
    "#embedding_path = \"../data/glove.6B.200d.txt.gz\"\n",
    "embedding_path = \"../data/glove.combined.300d.txt.gz\"\n",
    "embedding_tensor, word_to_indx = dr.getEmbeddingTensor(embedding_path)\n",
    "\n",
    "ids_corpus = dr.map_corpus(corpus, word_to_indx, kernel_width = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = torch.load(\"cnn_model\") # error when loading\n",
    "#model = torch.load(\"models_lr0.0003/model_epoch15\") # best to now is epoch 7: 0.474, 0.466\n",
    "model = torch.load(\"model_epoch1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../src/lstm.py:26: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greately increasing memory usage. To compact weights again call flatten_parameters().\n",
      "  output, hn = self.lstm(x) # hidden and cells are zero\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.567664057385\n"
     ]
    }
   ],
   "source": [
    "eval_path = \"../data_Android/dev_android.txt\"\n",
    "eval_anno = dr.read_annotations(eval_path, K_neg = -1, prune_pos_cnt = -1)\n",
    "eval_set = dr.create_dev_set(ids_corpus, eval_anno)\n",
    "\n",
    "z = run_epoch(eval_set, False, model, None)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using model_epoch...\n",
    "# 1: 0.567664057385\n",
    "# 2: 0.508170392997\n",
    "# 3: 0.422351891972\n",
    "# 4: 0.407533293215\n",
    "# 5: 0.415909610287\n",
    "# 6: 0.3984243719\n",
    "# 7: 0.425630836314\n",
    "# 8: 0.419762750268\n",
    "# 9: 0.412219429248\n",
    "#10: 0.423556593671\n",
    "#11: 0.4314310939\n",
    "\n",
    "#15: 0.366902339517"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../src/lstm.py:26: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greately increasing memory usage. To compact weights again call flatten_parameters().\n",
      "  output, hn = self.lstm(x) # hidden and cells are zero\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.537318239591\n"
     ]
    }
   ],
   "source": [
    "eval_path = \"../data_Android/test_android.txt\"\n",
    "eval_anno = dr.read_annotations(eval_path, K_neg = -1, prune_pos_cnt = -1)\n",
    "eval_set = dr.create_dev_set(ids_corpus, eval_anno)\n",
    "\n",
    "z = run_epoch(eval_set, False, model, None)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
